{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Getting started\n",
    "\n",
    "### CLEF 2025 - CheckThat! Lab  - Task 4 Scientific Web Discourse - Subtask 4b (Scientific Claim Source Retrieval)\n",
    "\n",
    "This notebook enables participants of subtask 4b to quickly get started. It includes the following:\n",
    "- Code to upload data, including:\n",
    "    - code to upload the collection set (CORD-19 academic papers' metadata)\n",
    "    - code to upload the query set (tweets with implicit references to CORD-19 papers)\n",
    "- Code to run a baseline retrieval model (BM25)\n",
    "- Code to evaluate the baseline model\n",
    "\n",
    "Participants are free to use this notebook and add their own models for the competition."
   ],
   "id": "82ec4f889fd77ca4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1) Importing data",
   "id": "5f5c15530b4d160"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "id": "6727cc1de865805d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.a) Import the collection set\n",
    "The collection set contains metadata of CORD-19 academic papers.\n",
    "\n",
    "The preprocessed and filtered CORD-19 dataset is available on the Gitlab repository here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
    "\n",
    "Participants should first download the file then upload it on the Google Colab session with the following steps.\n"
   ],
   "id": "e2c2af7de4044558"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1) Download the collection set from the Gitlab repository: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
    "# 2) Drag and drop the downloaded file to the \"Files\" section (left vertical menu on Colab)\n",
    "# 3) Modify the path to your local file path\n",
    "PATH_COLLECTION_DATA = 'subtask4b_collection_data.pkl' #MODIFY PATH"
   ],
   "id": "5598fa2cc83dca1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)",
   "id": "90e0262985810f93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_collection.info()",
   "id": "15d9161d86c25382"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_collection.head()",
   "id": "41895062faaefdd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.b) Import the query set\n",
    "\n",
    "The query set contains tweets with implicit references to academic papers from the collection set.\n",
    "\n",
    "The preprocessed query set is available on the Gitlab repository here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
    "\n",
    "Participants should first download the file then upload it on the Google Colab session with the following steps."
   ],
   "id": "2e97d4a21ca4ddcf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1) Download the query tweets from the Gitlab repository: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b?ref_type=heads\n",
    "# 2) Drag and drop the downloaded file to the \"Files\" section (left vertical menu on Colab)\n",
    "# 3) Modify the path to your local file path\n",
    "PATH_QUERY_TRAIN_DATA = 'subtask4b_query_tweets_train.tsv' #MODIFY PATH\n",
    "PATH_QUERY_DEV_DATA = 'subtask4b_query_tweets_dev.tsv' #MODIFY PATH"
   ],
   "id": "8aa9698bd95006a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')"
   ],
   "id": "9c46038a30903c08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_query_train.head()",
   "id": "805bae03d167a39e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_query_train.info()",
   "id": "cf0667d842ffbc67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_query_dev.head()",
   "id": "2745cf262aacc5c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_query_dev.info()",
   "id": "743f47d49126cae2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2) Running the baseline\n",
    "The following code runs a BM25 baseline.\n"
   ],
   "id": "8b007f402c53f7f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install rank_bm25\n",
    "from rank_bm25 import BM25Okapi\n"
   ],
   "id": "5a7e192ce38c585e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create the BM25 corpus\n",
    "corpus = df_collection[:][['title', 'abstract']].apply(lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "cord_uids = df_collection[:]['cord_uid'].tolist()\n",
    "tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ],
   "id": "ee5e90cec2a658be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_top_cord_uids(query):\n",
    "  text2bm25top = {}\n",
    "  if query in text2bm25top.keys():\n",
    "      return text2bm25top[query]\n",
    "  else:\n",
    "      tokenized_query = query.split(' ')\n",
    "      doc_scores = bm25.get_scores(tokenized_query)\n",
    "      indices = np.argsort(-doc_scores)[:5]\n",
    "      bm25_topk = [cord_uids[x] for x in indices]\n",
    "\n",
    "      text2bm25top[query] = bm25_topk\n",
    "      return bm25_topk\n"
   ],
   "id": "33b523ecac6ac6e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Retrieve topk candidates using the BM25 model\n",
    "df_query_train['bm25_topk'] = df_query_train['tweet_text'].apply(lambda x: get_top_cord_uids(x))\n",
    "df_query_dev['bm25_topk'] = df_query_dev['tweet_text'].apply(lambda x: get_top_cord_uids(x))"
   ],
   "id": "7217d31e01a8891"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3) Evaluating the baseline\n",
    "The following code evaluates the BM25 retrieval baseline on the query set using the Mean Reciprocal Rank score (MRR@5)."
   ],
   "id": "3417274c4468c0ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        #performances.append(data[\"in_topx\"].mean())\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance\n"
   ],
   "id": "f3e7fd4fe0b2ede1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "results_train = get_performance_mrr(df_query_train, 'cord_uid', 'bm25_topk')\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'bm25_topk')\n",
    "# Printed MRR@k results in the following format: {k: MRR@k}\n",
    "print(f\"Results on the train set: {results_train}\")\n",
    "print(f\"Results on the dev set: {results_dev}\")"
   ],
   "id": "a24f3b989792f823"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4) Exporting results to prepare the submission on Codalab",
   "id": "3629fa94fe8b9966"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_query_dev['preds'] = df_query_dev['bm25_topk'].apply(lambda x: x[:5])",
   "id": "c55f6b770b23cc95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_query_dev[['post_id', 'preds']].to_csv('predictions.tsv', index=None, sep='\\t')",
   "id": "5cc97168f6d1cd02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2c002f3411f62195"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
